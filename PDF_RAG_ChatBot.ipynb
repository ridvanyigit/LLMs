{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hD86OA4AusXzAipS1Tn8naDc6qcpoadH",
      "authorship_tag": "ABX9TyMqgKuVtT2yyxHHhIrWosMU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridvanyigit/LLMs/blob/main/PDF_RAG_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import gradio as gr\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.callbacks import StdOutCallbackHandler"
      ],
      "metadata": {
        "id": "NwLu1SH8rY0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîê API Key\n",
        "load_dotenv(override=True)\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
      ],
      "metadata": {
        "id": "-kq5HoII9QMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"knowledge-base/your-pdf-file.pdf\"\n",
        "db_name = \"vector_db\"\n",
        "model_name = \"gpt-4o\""
      ],
      "metadata": {
        "id": "1i85g7tI9QNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö PDF y√ºkleyici\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "YVyMMzSk9QPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÇÔ∏è Chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "8UGT-Qub9QQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîé Embedding + Chroma DB\n",
        "embeddings = OpenAIEmbeddings()\n",
        "if os.path.exists(db_name):\n",
        "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=db_name)\n",
        "vectorstore.persist()"
      ],
      "metadata": {
        "id": "8kGtB2yP9QSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Memory, LLM ve retriever setup\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "llm = ChatOpenAI(model_name=model_name, temperature=0.7)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
        "\n",
        "# üßµ Callback, LLM background\n",
        "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    callbacks=[StdOutCallbackHandler()]\n",
        ")"
      ],
      "metadata": {
        "id": "4iX6HNUx9QTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üí¨ Gradio Chat Interface function\n",
        "def chat(question, history):\n",
        "    result = conversation_chain.invoke({\"question\": question})\n",
        "    return result[\"answer\"]"
      ],
      "metadata": {
        "id": "N8GMzv8W9QVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ Run UI\n",
        "gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
      ],
      "metadata": {
        "id": "R3QgbQXZ9QWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6nQLvqI9Qfy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}