{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdPxUDMPF9Uf5pP3NlKPCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridvanyigit/LLMs/blob/main/pdf_RAG_Gradio_App_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.SECTION**"
      ],
      "metadata": {
        "id": "hsyacaO9N7pz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TC-P6c5cd6XC"
      },
      "outputs": [],
      "source": [
        "# @title Install Required Libraries\n",
        "\n",
        "!pip install langchain langchain-openai langchain-chroma\n",
        "!pip install PyPDF2\n",
        "!pip install plotly\n",
        "!pip install scikit-learn\n",
        "!pip install gradio\n",
        "!pip install python-dotenv\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title imports\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from dotenv import load_dotenv\n",
        "import gradio as gr\n",
        "from google.colab import drive, files\n",
        "import PyPDF2\n",
        "import io"
      ],
      "metadata": {
        "id": "MfcGagULeI0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title imports for langchain, plotly and Chroma\n",
        "\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "S3-jXDQDeI9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Colab-Optimized Settings\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "db_name = \"vector_db\"\n",
        "CHUNK_SIZE = 800\n",
        "CHUNK_OVERLAP = 150\n",
        "MAX_RETRIEVAL_DOCS = 10"
      ],
      "metadata": {
        "id": "kEZVv4HieJAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mount Google Drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive connected successfully!\")\n",
        "\n",
        "# Set OpenAI API Key (from Colab Secrets)\n",
        "\n",
        "print(\"üîë Setting OpenAI API Key...\")\n",
        "from google.colab import userdata\n",
        "try:\n",
        "    api_key = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    print(\"‚úÖ API Key successfully retrieved from Colab Secrets!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Could not retrieve API Key from Colab Secrets!\")\n",
        "    print(\"Please go to the üîë Secrets section in the left menu and add 'OPENAI_API_KEY'\")\n",
        "    api_key = input(\"Alternatively, enter your API Key here: \")\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    print(\"‚úÖ API Key set manually!\")\n"
      ],
      "metadata": {
        "id": "zZ7BK_K1eJD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.SECTION**"
      ],
      "metadata": {
        "id": "bfoFosaQNvpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Read PDF Files\n",
        "\n",
        "def read_pdf_files():\n",
        "    pdf_folder = \"/content/drive/MyDrive/MyPDFs\"\n",
        "    documents = []\n",
        "\n",
        "    print(f\"üìÇ Reading PDF files from: {pdf_folder}\")\n",
        "\n",
        "    # Find all PDF files in the folder\n",
        "    pdf_files = glob.glob(os.path.join(pdf_folder, \"*.pdf\"))\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"‚ùå No PDF files found!\")\n",
        "        print(f\"Folder contents: {os.listdir(pdf_folder) if os.path.exists(pdf_folder) else 'Folder not found'}\")\n",
        "        return []\n",
        "\n",
        "    print(f\"üìÑ Found {len(pdf_files)} PDF files\\n\")\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        try:\n",
        "            filename = os.path.basename(pdf_file)\n",
        "            print(f\"üìñ Reading: {filename}\")\n",
        "\n",
        "            with open(pdf_file, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                text = \"\"\n",
        "\n",
        "                for page_num in range(len(pdf_reader.pages)):\n",
        "                    page = pdf_reader.pages[page_num]\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "\n",
        "                if text.strip():  # If not empty\n",
        "                    doc = Document(\n",
        "                        page_content=text,\n",
        "                        metadata={\n",
        "                            \"source\": filename,\n",
        "                            \"doc_type\": \"certificate\",  # Certificate/Diploma category\n",
        "                            \"file_path\": pdf_file\n",
        "                        }\n",
        "                    )\n",
        "                    documents.append(doc)\n",
        "                    print(f\"‚úÖ {filename} read successfully ({len(text)} characters)\\n\")\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è {filename} is empty or unreadable\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error reading {filename}: {str(e)}\")\n",
        "\n",
        "    return documents"
      ],
      "metadata": {
        "id": "d6NY8qsjeJKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload PDF Files\n",
        "\n",
        "documents = read_pdf_files()\n",
        "\n",
        "if not documents:\n",
        "    print(\"‚ùå No documents could be loaded! Please check the file paths.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"üìö A total of {len(documents)} documents loaded\")"
      ],
      "metadata": {
        "id": "X020GH3GeJNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Split Documents into Chunks\n",
        "\n",
        "print(\"‚úÇÔ∏è Splitting documents into chunks...\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"üìù Total {len(chunks)} chunks created\")"
      ],
      "metadata": {
        "id": "CWNbQnZteJQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create Vector Store\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# If you want to use free embeddings, activate the lines below:\n",
        "#embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "OhphbcTKeJTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete Existing Database\n",
        "\n",
        "if os.path.exists(db_name):\n",
        "    import shutil\n",
        "    shutil.rmtree(db_name)\n",
        "\n",
        "# Create Vector Store\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=db_name\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Vectorstore created with {vectorstore._collection.count()} documents\")\n",
        "\n",
        "# Vector Analysis\n",
        "\n",
        "print(\"üìä Performing vector analysis...\")\n",
        "\n",
        "collection = vectorstore._collection\n",
        "count = collection.count()\n",
        "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
        "dimensions = len(sample_embedding)\n",
        "\n",
        "print(f\"üìà {count:,} vectors, {dimensions:,} dimensions\")"
      ],
      "metadata": {
        "id": "Vx5IiK7keJWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2D Visualization\n",
        "\n",
        "def create_visualizations():\n",
        "    print(\"üé® Preparing visualizations...\")\n",
        "\n",
        "    result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
        "    vectors = np.array(result['embeddings'])\n",
        "    documents_text = result['documents']\n",
        "    metadatas = result['metadatas']\n",
        "\n",
        "    # Color by file names\n",
        "    sources = [metadata['source'] for metadata in metadatas]\n",
        "    unique_sources = list(set(sources))\n",
        "    color_map = {source: f\"hsl({i*360/len(unique_sources)}, 70%, 60%)\"\n",
        "                for i, source in enumerate(unique_sources)}\n",
        "    colors = [color_map[source] for source in sources]\n",
        "\n",
        "    # 2D t-SNE\n",
        "    print(\"üìâ Calculating 2D t-SNE...\")\n",
        "    tsne_2d = TSNE(n_components=2, random_state=42, perplexity=min(30, len(vectors)-1))\n",
        "    reduced_2d = tsne_2d.fit_transform(vectors)\n",
        "\n",
        "    # 2D Plot\n",
        "    fig_2d = go.Figure(data=[go.Scatter(\n",
        "        x=reduced_2d[:, 0],\n",
        "        y=reduced_2d[:, 1],\n",
        "        mode='markers',\n",
        "        marker=dict(size=8, color=colors, opacity=0.7),\n",
        "        text=[f\"File: {s}<br>Text: {d[:150]}...\" for s, d in zip(sources, documents_text)],\n",
        "        hoverinfo='text'\n",
        "    )])\n",
        "\n",
        "    fig_2d.update_layout(\n",
        "        title='üìä 2D Vector Map of Your PDF Documents',\n",
        "        xaxis_title='Dimension 1',\n",
        "        yaxis_title='Dimension 2',\n",
        "        width=800,\n",
        "        height=600,\n",
        "        margin=dict(r=20, b=10, l=10, t=40)\n",
        "    )\n",
        "    fig_2d.show()\n",
        "\n",
        "    # 3D t-SNE (only if enough data)\n",
        "    if len(vectors) > 10:\n",
        "        print(\"üìà Calculating 3D t-SNE...\")\n",
        "        tsne_3d = TSNE(n_components=3, random_state=42, perplexity=min(30, len(vectors)-1))\n",
        "        reduced_3d = tsne_3d.fit_transform(vectors)\n",
        "\n",
        "        fig_3d = go.Figure(data=[go.Scatter3d(\n",
        "            x=reduced_3d[:, 0],\n",
        "            y=reduced_3d[:, 1],\n",
        "            z=reduced_3d[:, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(size=6, color=colors, opacity=0.8),\n",
        "            text=[f\"File: {s}<br>Text: {d[:150]}...\" for s, d in zip(sources, documents_text)],\n",
        "            hoverinfo='text'\n",
        "        )])\n",
        "\n",
        "        fig_3d.update_layout(\n",
        "            title='üìä 3D Vector Map of Your PDF Documents',\n",
        "            scene=dict(xaxis_title='Dimension 1', yaxis_title='Dimension 2', zaxis_title='Dimension 3'),\n",
        "            width=900,\n",
        "            height=700,\n",
        "            margin=dict(r=20, b=10, l=10, t=40)\n",
        "        )\n",
        "        fig_3d.show()\n",
        "\n",
        "# Create visualizations\n",
        "create_visualizations()"
      ],
      "metadata": {
        "id": "DoxkSOTieJdO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B√ñL√úM 3"
      ],
      "metadata": {
        "id": "KWkzSs8GQmhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set up RAG Chain\n",
        "\n",
        "print(\"ü§ñ Setting up AI Chat system...\")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": MAX_RETRIEVAL_DOCS})\n",
        "\n",
        "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "_zrsXoDHeJgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test question\n",
        "\n",
        "test_query = \"Who is Ridvan Yigit?\"\n",
        "result = conversation_chain.invoke({\"question\": test_query})\n",
        "\n",
        "print(f\"Test Answer: {result['answer']}\")\n",
        "print(\"‚úÖ System successfully set up!\")"
      ],
      "metadata": {
        "id": "G85MrKrReJh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Debug and troubleshooting version with callback\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîç DEBUG AND TROUBLESHOOTING SECTION\")\n",
        "print(\"=\"*50)\n",
        "print(\"If you experience issues in the system, run the code below:\")\n",
        "print(\"This code shows how the RAG system works in the background\\n\")\n",
        "\n",
        "def debug_rag_system():\n",
        "    \"\"\"Debug the RAG system with callbacks\"\"\"\n",
        "    from langchain_core.callbacks import StdOutCallbackHandler\n",
        "\n",
        "    print(\"üîß Setting up the RAG system in debug mode...\")\n",
        "\n",
        "    # LLM with callback for debugging\n",
        "    debug_llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
        "    debug_memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "    debug_retriever = vectorstore.as_retriever(search_kwargs={\"k\": MAX_RETRIEVAL_DOCS})\n",
        "\n",
        "    # Conversation chain with callback handler\n",
        "    debug_conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=debug_llm,\n",
        "        retriever=debug_retriever,\n",
        "        memory=debug_memory,\n",
        "        callbacks=[StdOutCallbackHandler()]  # This line shows background processes\n",
        "    )\n",
        "\n",
        "    print(\"\\nüîç Running debug test query...\")\n",
        "    print(\"Below you will see step-by-step how the RAG system works:\\n\")\n",
        "\n",
        "    debug_query = \"Which certificates are there and from which institutions?\"\n",
        "    debug_result = debug_conversation_chain.invoke({\"question\": debug_query})\n",
        "\n",
        "    print(f\"\\nüìã Debug Test Result:\")\n",
        "    print(f\"Question: {debug_query}\")\n",
        "    print(f\"Answer: {debug_result['answer']}\")\n",
        "    print(\"\\n‚úÖ Debug test completed!\")\n",
        "\n",
        "    return debug_conversation_chain\n",
        "\n",
        "# Make the debug function ready to use\n",
        "print(\"üí° If you face issues, run this command:\")\n",
        "print(\"debug_chain = debug_rag_system()\")\n",
        "print(\"This will show you detailed how the system works.\\n\")"
      ],
      "metadata": {
        "id": "U8qybURUtqmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_chain = debug_rag_system()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "--mnp20PQ_Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Additional function to test retrieval quality\n",
        "\n",
        "def test_retrieval(query, k=5):\n",
        "    \"\"\"Test retrieval results for a given query\"\"\"\n",
        "    print(f\"üîç Retrieval Test - Query: '{query}'\")\n",
        "    print(f\"üìä Fetching top {k} closest document chunks...\\n\")\n",
        "\n",
        "    docs = vectorstore.similarity_search(query, k=k)\n",
        "\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        print(f\"üìÑ Result {i}:\")\n",
        "        print(f\"   File: {doc.metadata.get('source', 'Unknown')}\")\n",
        "        print(f\"   Content: {doc.page_content[:200]}...\")\n",
        "        print(f\"   Character Count: {len(doc.page_content)}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    return docs\n",
        "\n",
        "print(\"üîß Additional debug function:\")\n",
        "print(\"test_retrieval('certificate', k=3)  # Tests retrieval quality\")\n",
        "print(\"test_retrieval('diploma', k=5)     # Tests diploma searches\\n\")"
      ],
      "metadata": {
        "id": "IuK70UPGt3vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Chat Interface\n",
        "\n",
        "def chat(message, history):\n",
        "    \"\"\"Gradio chat function\"\"\"\n",
        "    try:\n",
        "        result = conversation_chain.invoke({\"question\": message})\n",
        "        return result[\"answer\"]\n",
        "    except Exception as e:\n",
        "        return f\"Sorry, an error occurred: {str(e)}\"\n",
        "\n",
        "# Start Gradio interface\n",
        "\n",
        "print(\"üöÄ Starting chat interface...\")\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.ChatInterface(\n",
        "    chat,\n",
        "    type=\"messages\",\n",
        "    title=\"üìö Certificate & Diploma AI Assistant\",\n",
        "    description=\"You can query information in your PDF documents. You can ask questions in Turkish!\",\n",
        "    examples=[\n",
        "        \"What certificates do I have?\",\n",
        "        \"What is the latest certificate I received?\",\n",
        "        \"From which institutions did I get certificates?\",\n",
        "        \"Summarize the content of my certificates\",\n",
        "        \"What topics are covered in these documents?\"\n",
        "    ],\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "# Launch interface\n",
        "\n",
        "interface.launch(\n",
        "    share=True,  # Create public link\n",
        "    inbrowser=True,\n",
        "    height=600\n",
        ")"
      ],
      "metadata": {
        "id": "SH6jOa7veJi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZrFgYplGeJ2d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
