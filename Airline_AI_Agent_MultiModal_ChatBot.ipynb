{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7wh6eoe3JYIldIapbUPbM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridvanyigit/LLMs/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.SECTION**\n",
        "\n",
        "##Airline AI Assistant\n",
        "\n",
        "Jupyter Lab (Environment)"
      ],
      "metadata": {
        "id": "tyYVUVnWf3bk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntP6mm7KfyNe"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "openai = OpenAI()"
      ],
      "metadata": {
        "id": "KBxWzauegDO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
        "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
        "system_message += \"Always be accurate. If you don't know the answer, say so.\""
      ],
      "metadata": {
        "id": "LKUivLqngDN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "id": "CnI_g_RmgDMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
        "\n",
        "def get_ticket_price(destination_city):\n",
        "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
        "    city = destination_city.lower()\n",
        "    return ticket_prices.get(city, \"Unknown\")"
      ],
      "metadata": {
        "id": "sQ_5R-gygDLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ticket_price(\"London\")"
      ],
      "metadata": {
        "id": "2K5VsUoBgDIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There's a particular dictionary structure that's required to describe our function:\n",
        "\n",
        "price_function = {\n",
        "    \"name\": \"get_ticket_price\",\n",
        "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"destination_city\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The city that the customer wants to travel to\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"destination_city\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "46Hlc3oAgDHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [{\"type\": \"function\", \"function\": price_function}]"
      ],
      "metadata": {
        "id": "42DmLAFEgDGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
        "\n",
        "    if response.choices[0].finish_reason==\"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        response, city = handle_tool_call(message)\n",
        "        messages.append(message)\n",
        "        messages.append(response)\n",
        "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "LyIqhl1cgDEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We have to write that function handle_tool_call:\n",
        "\n",
        "def handle_tool_call(message):\n",
        "    tool_call = message.tool_calls[0]\n",
        "    arguments = json.loads(tool_call.function.arguments)\n",
        "    city = arguments.get('destination_city')\n",
        "    price = get_ticket_price(city)\n",
        "    response = {\n",
        "        \"role\": \"tool\",\n",
        "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
        "        \"tool_call_id\": tool_call.id\n",
        "    }\n",
        "    return response, city"
      ],
      "metadata": {
        "id": "2sE3uBg9gDDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "id": "Jggr6-gJgDB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.SECTION**\n",
        "## Multi Modal"
      ],
      "metadata": {
        "id": "UftGQg_bgwcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some imports for handling images\n",
        "\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "4qT_SEIbgDBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def artist(city):\n",
        "    image_response = openai.images.generate(\n",
        "            model=\"dall-e-3\",\n",
        "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
        "            size=\"1024x1024\",\n",
        "            n=1,\n",
        "            response_format=\"b64_json\",\n",
        "        )\n",
        "    image_base64 = image_response.data[0].b64_json\n",
        "    image_data = base64.b64decode(image_base64)\n",
        "    return Image.open(BytesIO(image_data))"
      ],
      "metadata": {
        "id": "ldEqnBfKgC_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = artist(\"New York City\")\n",
        "display(image)"
      ],
      "metadata": {
        "id": "rOezgI9kgC-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio (NOTE - Audio is optional)\n",
        "\n",
        "And let's make a function talker that uses OpenAI's speech model to generate Audio\n",
        "\n",
        "### Troubleshooting Audio issues\n",
        "\n",
        "If you have any problems running this code below (like a FileNotFound error, or a warning of a missing package), you may need to install FFmpeg, a very popular audio utility.\n",
        "\n",
        "**For PC Users**\n",
        "\n",
        "Detailed instructions are [here](https://chatgpt.com/share/6724efee-6b0c-8012-ac5e-72e2e3885905) and summary instructions:\n",
        "\n",
        "1. Download FFmpeg from the official website: https://ffmpeg.org/download.html\n",
        "\n",
        "2. Extract the downloaded files to a location on your computer (e.g., `C:\\ffmpeg`)\n",
        "\n",
        "3. Add the FFmpeg bin folder to your system PATH:\n",
        "- Right-click on 'This PC' or 'My Computer' and select 'Properties'\n",
        "- Click on 'Advanced system settings'\n",
        "- Click on 'Environment Variables'\n",
        "- Under 'System variables', find and edit 'Path'\n",
        "- Add a new entry with the path to your FFmpeg bin folder (e.g., `C:\\ffmpeg\\bin`)\n",
        "- Restart your command prompt, and within Jupyter Lab do Kernel -> Restart kernel, to pick up the changes\n",
        "\n",
        "4. Open a new command prompt and run this to make sure it's installed OK\n",
        "`ffmpeg -version`\n",
        "\n",
        "**For Mac Users**\n",
        "\n",
        "1. Install homebrew if you don't have it already by running this in a Terminal window and following any instructions:  \n",
        "`/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"`\n",
        "\n",
        "2. Then install FFmpeg with `brew install ffmpeg`\n",
        "\n",
        "3. Verify your installation with `ffmpeg -version` and if everything is good, within Jupyter Lab do Kernel -> Restart kernel to pick up the changes"
      ],
      "metadata": {
        "id": "rs4RPh0IhGTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -version\n",
        "!ffprobe -version\n",
        "!ffplay -version"
      ],
      "metadata": {
        "id": "RgY2aKNvgC8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "      model=\"tts-1\",\n",
        "      voice=\"onyx\",    # Also, try replacing onyx with alloy\n",
        "      input=message\n",
        "    )\n",
        "\n",
        "    audio_stream = BytesIO(response.content)\n",
        "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
        "    play(audio)"
      ],
      "metadata": {
        "id": "FvQgYMZDgC7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "talker(\"Well, hi there\")"
      ],
      "metadata": {
        "id": "TeKV80LGh2JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE : For PC Users\n",
        "\n",
        "# Version1:\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"onyx\",\n",
        "        input=message)\n",
        "\n",
        "    audio_stream = BytesIO(response.content)\n",
        "    output_filename = \"output_audio.mp3\"\n",
        "    with open(output_filename, \"wb\") as f:\n",
        "        f.write(audio_stream.read())\n",
        "\n",
        "    # Play the generated audio\n",
        "    display(Audio(output_filename, autoplay=True))\n",
        "\n",
        "talker(\"Well, hi there\")\n",
        "\n",
        "# Version2:\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from io import BytesIO\n",
        "\n",
        "def talker(message):\n",
        "    # Set a custom directory for temporary files on Windows\n",
        "    custom_temp_dir = os.path.expanduser(\"~/Documents/temp_audio\")\n",
        "    os.environ['TEMP'] = custom_temp_dir  # You can also use 'TMP' if necessary\n",
        "\n",
        "    # Create the folder if it doesn't exist\n",
        "    if not os.path.exists(custom_temp_dir):\n",
        "        os.makedirs(custom_temp_dir)\n",
        "\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"onyx\",  # Also, try replacing onyx with alloy\n",
        "        input=message\n",
        "    )\n",
        "\n",
        "    audio_stream = BytesIO(response.content)\n",
        "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
        "\n",
        "    play(audio)\n",
        "\n",
        "talker(\"Well hi there\")"
      ],
      "metadata": {
        "id": "4oUTlpj-h2HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
        "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
        "    image = None\n",
        "\n",
        "    if response.choices[0].finish_reason==\"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        response, city = handle_tool_call(message)\n",
        "        messages.append(message)\n",
        "        messages.append(response)\n",
        "        image = artist(city)\n",
        "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
        "\n",
        "    reply = response.choices[0].message.content\n",
        "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
        "\n",
        "    # Comment out or delete the next line if you'd rather skip Audio for now..\n",
        "    talker(reply)\n",
        "\n",
        "    return history, image"
      ],
      "metadata": {
        "id": "0EM6YnfHh2FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as ui:\n",
        "    with gr.Row():\n",
        "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
        "        image_output = gr.Image(height=500)\n",
        "    with gr.Row():\n",
        "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
        "    with gr.Row():\n",
        "        clear = gr.Button(\"Clear\")\n",
        "\n",
        "    def do_entry(message, history):\n",
        "        history += [{\"role\":\"user\", \"content\":message}]\n",
        "        return \"\", history\n",
        "\n",
        "    entry.submit(\n",
        "        do_entry,\n",
        "        inputs=[entry, chatbot],\n",
        "        outputs=[entry, chatbot]\n",
        "    ).then(\n",
        "        chat,\n",
        "        inputs=chatbot,\n",
        "        outputs=[chatbot, image_output]\n",
        "    )\n",
        "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ],
      "metadata": {
        "id": "6u_yynz9h2C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EWnEGlEQh2Ac"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
